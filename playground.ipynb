{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "import random\n",
    "# import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import segmentation_models_pytorch as smp\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from sklearn import cluster\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Replace with your own NASA API key\n",
    "NASA_KEY = \"\"\n",
    "IMG_DIM = 0.1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################## Download NASA sat image\n",
    "def download_satellite_image(lon, lat, date):\n",
    "    \"\"\"\n",
    "    Downloads a satellite image from the NASA API for a specific longitude, latitude, and date.\n",
    "\n",
    "    Args:\n",
    "        lon (float): The longitude of the location to download the image for.\n",
    "        lat (float): The latitude of the location to download the image for.\n",
    "        date (str): The date in YYYY-MM-DD format of the image to download.\n",
    "\n",
    "    Returns:\n",
    "        Image: A PIL Image object containing the downloaded satellite image.\n",
    "    \"\"\"\n",
    "    img_url = f\"https://api.nasa.gov/planetary/earth/imagery?lon={lon}&lat={lat}&date={date}&dim={IMG_DIM}&api_key={NASA_KEY}\"\n",
    "    response = requests.get(img_url)\n",
    "    image = Image.open(io.BytesIO(response.content))\n",
    "    return image\n",
    "\n",
    "########################## Process image\n",
    "def process_img(image, resize=(256, 256)):\n",
    "    \"\"\"\n",
    "    Preprocesses a PIL image for use in a machine learning model.\n",
    "\n",
    "    Args:\n",
    "        image (PIL.Image.Image): The input image to preprocess.\n",
    "        resize (tuple[int, int]): The target size of the image after resizing. Defaults to (256, 256).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 3D NumPy array representing the preprocessed image, with pixel values normalized to [0, 1].\n",
    "\n",
    "    \"\"\"\n",
    "    #image = enhance_image(image)\n",
    "    image = image.resize(resize)\n",
    "    # Convert the image to a numpy array and normalize its values\n",
    "    img_array = np.array(image).astype(np.float32) / 255\n",
    "    return img_array\n",
    "\n",
    "########################## Improve image clarity\n",
    "# def enhance_image(image):\n",
    "#     \"\"\"\n",
    "#     Enhances the contrast of a PIL image using the CLAHE (Contrast Limited Adaptive Histogram Equalization) algorithm.\n",
    "\n",
    "#     Args:\n",
    "#         image (PIL.Image.Image): The input RGB image to enhance.\n",
    "\n",
    "#     Returns:\n",
    "#         PIL.Image.Image: A new PIL image with enhanced contrast.\n",
    "\n",
    "#     \"\"\"\n",
    "#     img_array = np.array(image)\n",
    "\n",
    "#     # Convert to LAB color space\n",
    "#     lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "#     # Split into channels\n",
    "#     l, a, b = cv2.split(lab)\n",
    "\n",
    "#     # Apply histogram equalization to the L channel\n",
    "#     clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "#     cl = clahe.apply(l)\n",
    "\n",
    "#     # Merge the channels back into the LAB image\n",
    "#     lab = cv2.merge((cl, a, b))\n",
    "\n",
    "#     # Convert back to RGB color space\n",
    "#     enhanced_image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "#     return Image.fromarray(enhanced_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def segment_image_restnet(image_array, use_imagenet=False):\n",
    "    \"\"\"\n",
    "    Segments an RGB image using a ResNet-based U-Net model.\n",
    "\n",
    "    Args:\n",
    "        image_array (np.ndarray): A 3D NumPy array representing the input RGB image.\n",
    "        use_imagenet (bool): Whether to use ResNet50 pretrained on ImageNet. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 2D NumPy array representing the segmentation mask of the input image, with pixel values in {0, 1}.\n",
    "\n",
    "    \"\"\"\n",
    "    # Ensure the model runs on CPU\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    if use_imagenet:\n",
    "        model = smp.Unet(encoder_name='resnet50', encoder_weights='imagenet', classes=2, activation='softmax').to(device)\n",
    "    else:\n",
    "        model = smp.Unet('resnet18', classes=2, activation='softmax').to(device)\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    input_tensor = torch.from_numpy(image_array.transpose(2, 0, 1)).unsqueeze(0).float().to(device)\n",
    "\n",
    "    # Run the model on the input image\n",
    "    with torch.no_grad():\n",
    "        prediction = model(input_tensor)\n",
    "\n",
    "    output_np = prediction.squeeze().argmax(dim=0).numpy()\n",
    "    return output_np\n",
    "\n",
    "def kmeans_cluster(img_array, n_clusters):\n",
    "    \"\"\"\n",
    "    Performs k-means clustering on a single-band image.\n",
    "\n",
    "    Args:\n",
    "        img_array (np.ndarray): A 2D NumPy array representing the input single-band image.\n",
    "        n_clusters (int): The number of clusters to use for the k-means algorithm.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 2D NumPy array representing the clustering labels of the input image.\n",
    "\n",
    "    \"\"\"\n",
    "    img = img_array[:, :, 0]  # Just get one band of the image\n",
    "    X = img.reshape((-1, 1))\n",
    "    k_means = cluster.KMeans(n_clusters=n_clusters)\n",
    "    k_means.fit(X)\n",
    "    segmentation = k_means.labels_\n",
    "    segmentation = segmentation.reshape(img.shape)\n",
    "\n",
    "    return segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Map overlay image\n",
    "def create_colored_mask_image(segmentation, n_clusters):\n",
    "    \"\"\"\n",
    "    Creates a color mask image from a segmentation label image.\n",
    "\n",
    "    Args:\n",
    "        segmentation (np.ndarray): A 2D NumPy array representing the segmentation label image.\n",
    "        n_clusters (int): The number of clusters used to generate the segmentation label image.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image.Image: A new PIL Image object representing the color mask image.\n",
    "\n",
    "    \"\"\"\n",
    "    # Use the colors from the Plotly Viridis colorscale\n",
    "    colorscale = px.colors.sequential.Viridis\n",
    "\n",
    "    def hex_to_rgb(hex_color):\n",
    "        hex_color = hex_color.lstrip(\"#\")\n",
    "        return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))\n",
    "    rgb_colorscale = [hex_to_rgb(color) for color in colorscale]\n",
    "\n",
    "    # Interpolate the colorscale to have n_clusters colors\n",
    "    interpolated_colors = []\n",
    "    for i in range(n_clusters):\n",
    "        position = i / (n_clusters - 1) * (len(colorscale) - 1)\n",
    "        lower_color = rgb_colorscale[int(position)]\n",
    "        upper_color = rgb_colorscale[min(int(position) + 1, len(colorscale) - 1)]\n",
    "        ratio = position % 1\n",
    "        interpolated_color = tuple([int(lower_color[i] * (1 - ratio) + upper_color[i] * ratio) for i in range(3)])\n",
    "        interpolated_colors.append(interpolated_color)\n",
    "\n",
    "    colored_mask = np.zeros((segmentation.shape[0], segmentation.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for i, color in enumerate(interpolated_colors):\n",
    "        colored_mask[segmentation == i] = color\n",
    "\n",
    "    return Image.fromarray(colored_mask)\n",
    "\n",
    "\n",
    "def create_map_overlay(lon, lat, image=None, colored_mask=None):\n",
    "    \"\"\"\n",
    "    Creates a plotly figure with a marker at the specified longitude and latitude, and optionally overlays an image and/or a colored mask on a map.\n",
    "\n",
    "    Args:\n",
    "        lon (float): The longitude to center the map on.\n",
    "        lat (float): The latitude to center the map on.\n",
    "        image (Optional[np.ndarray, PIL.Image.Image]): A 3D NumPy array or PIL Image object representing an image to overlay on the map. Defaults to None.\n",
    "        colored_mask (Optional[np.ndarray, PIL.Image.Image]): A 3D NumPy array or PIL Image object representing a colored mask to overlay on the map. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        plotly.graph_objs._figure.Figure: A new plotly figure with the specified overlay(s) on the map.\n",
    "\n",
    "    \"\"\"\n",
    "    fig = go.Figure(go.Scattermapbox(\n",
    "        lat=[lat],\n",
    "        lon=[lon],\n",
    "        mode='lines',\n",
    "    ))\n",
    "    mapbox_layers = []\n",
    "    if image:\n",
    "        mapbox_layers += [{\n",
    "            'sourcetype': 'image',\n",
    "            'source': image,\n",
    "            'coordinates': [\n",
    "                [lon - IMG_DIM/2, lat + IMG_DIM/2],\n",
    "                [lon + IMG_DIM/2, lat + IMG_DIM/2],\n",
    "                [lon + IMG_DIM/2, lat - IMG_DIM/2],\n",
    "                [lon - IMG_DIM/2, lat - IMG_DIM/2],\n",
    "            ],\n",
    "            'opacity': 0.8, ## OPACITY\n",
    "        }]\n",
    "    if colored_mask:\n",
    "        mapbox_layers += [{\n",
    "            'sourcetype': 'image',\n",
    "            'source': colored_mask,\n",
    "            'coordinates': [\n",
    "                [lon - IMG_DIM/2, lat + IMG_DIM/2],\n",
    "                [lon + IMG_DIM/2, lat + IMG_DIM/2],\n",
    "                [lon + IMG_DIM/2, lat - IMG_DIM/2],\n",
    "                [lon - IMG_DIM/2, lat - IMG_DIM/2],\n",
    "            ],\n",
    "            'opacity': 0.6, ## OPACITY\n",
    "        }]\n",
    "    fig.update_layout(\n",
    "        mapbox_style='open-street-map',\n",
    "        mapbox_center_lat=lat,\n",
    "        mapbox_center_lon=lon,\n",
    "        mapbox_zoom=11.5,\n",
    "        mapbox_layers=mapbox_layers,\n",
    "        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n",
    "        width=512,\n",
    "        height=512,\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "########################## Interactive figure\n",
    "def create_colored_points(lon, lat, image_array, segmentation, n_clusters):\n",
    "    \"\"\"\n",
    "    Creates lists of latitude, longitude, and color values for plotting colored points on a map.\n",
    "\n",
    "    Args:\n",
    "        lon (float): The longitude to center the map on.\n",
    "        lat (float): The latitude to center the map on.\n",
    "        image_array (np.ndarray): A 3D NumPy array representing an image to sample points from.\n",
    "        segmentation (np.ndarray): A 2D NumPy array representing the clustering labels of the input image.\n",
    "        n_clusters (int): The number of clusters used to generate the clustering label image.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[float], List[float], List[str]]: A tuple of three lists representing the latitude, longitude, and color values of the colored points.\n",
    "\n",
    "    \"\"\"\n",
    "    cluster_colors = px.colors.qualitative.Plotly[:n_clusters]\n",
    "\n",
    "    lat_points = []\n",
    "    lon_points = []\n",
    "    colors = []\n",
    "\n",
    "    lat_step = IMG_DIM / image_array.shape[0]\n",
    "    lon_step = IMG_DIM / image_array.shape[1]\n",
    "\n",
    "    for i in range(image_array.shape[0]):\n",
    "        for j in range(image_array.shape[1]):\n",
    "            lat_points.append(lat + IMG_DIM/2 - i*lat_step)\n",
    "            lon_points.append(lon - IMG_DIM/2 + j*lon_step)\n",
    "            colors.append(cluster_colors[segmentation[i, j]])\n",
    "\n",
    "    return lat_points, lon_points, colors\n",
    "\n",
    "def create_interactive_map(lon, lat, lat_points, lon_points, colors):\n",
    "    \"\"\"\n",
    "    Creates an interactive plotly figure with colored markers at specified latitude and longitude points.\n",
    "\n",
    "    Args:\n",
    "        lon (float): The longitude to center the map on.\n",
    "        lat (float): The latitude to center the map on.\n",
    "        lat_points (List[float]): A list of latitude values for the colored markers.\n",
    "        lon_points (List[float]): A list of longitude values for the colored markers.\n",
    "        colors (List[str]): A list of color values for the colored markers.\n",
    "\n",
    "    Returns:\n",
    "        plotly.graph_objs._figure.Figure: A new interactive plotly figure with colored markers at the specified latitude and longitude points.\n",
    "\n",
    "    \"\"\"\n",
    "    fig = go.Figure(go.Scattermapbox(\n",
    "        lat=lat_points,\n",
    "        lon=lon_points,\n",
    "        mode='markers',\n",
    "        marker=dict(size=3, color=colors),\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        mapbox_style='open-street-map',\n",
    "        mapbox_center_lat=lat,\n",
    "        mapbox_center_lon=lon,\n",
    "        mapbox_zoom=11.5,\n",
    "        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n",
    "        width=512,\n",
    "        height=512,\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "########################## Cluster proportion figure / stats\n",
    "def calculate_class_proportions(segmentation, n_clusters):\n",
    "    \"\"\"\n",
    "    Calculates the proportion of pixels in each cluster in a clustering label image.\n",
    "\n",
    "    Args:\n",
    "        segmentation (np.ndarray): A 2D NumPy array representing the clustering labels of an image.\n",
    "        n_clusters (int): The number of clusters used to generate the clustering label image.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: A 1D NumPy array representing the proportion of pixels in each cluster.\n",
    "\n",
    "    \"\"\"\n",
    "    total_pixels = segmentation.size\n",
    "    class_counts = np.zeros(n_clusters, dtype=int)\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        class_counts[i] = np.sum(segmentation == i)\n",
    "\n",
    "    class_proportions = class_counts / total_pixels\n",
    "    return class_proportions\n",
    "\n",
    "def create_class_distribution_pie_chart(class_proportions):\n",
    "    \"\"\"\n",
    "    Creates a pie chart showing the distribution of pixels in each cluster.\n",
    "\n",
    "    Args:\n",
    "        class_proportions (np.ndarray): A 1D NumPy array representing the proportion of pixels in each cluster.\n",
    "\n",
    "    Returns:\n",
    "        plotly.graph_objs._figure.Figure: A new plotly pie chart figure showing the distribution of pixels in each cluster.\n",
    "\n",
    "    \"\"\"\n",
    "    cluster_ids = list(range(len(class_proportions)))\n",
    "    fig = go.Figure(go.Pie(\n",
    "        labels=cluster_ids,\n",
    "        values=class_proportions,\n",
    "        textinfo='label+percent',\n",
    "        insidetextorientation='radial',\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Class Distribution\",\n",
    "        width=600,\n",
    "        height=400,\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "interactive = False\n",
    "use_coordinates = True\n",
    "\n",
    "N_CLUSTERS = 4\n",
    "date = \"2019-01-01\"\n",
    "#lon, lat = 88.780777, 24.114852\n",
    "lon, lat = 89.007557, 24.515067\n",
    "image_path = \"sample_river.jpg\"\n",
    "# image_path = \"shasta_lake_2021_june_16.jpg\"\n",
    "\n",
    "if use_coordinates:\n",
    "    image = download_satellite_image(lon, lat, \"2018-01-01\")\n",
    "else:\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "image_array = process_img(image)\n",
    "segmentation = kmeans_cluster(image_array, N_CLUSTERS)\n",
    "#segmentation = segment_image_restnet(image_array, True)\n",
    "\n",
    "if interactive:\n",
    "    lat_points, lon_points, colors = create_colored_points(lon, lat, image_array, segmentation, N_CLUSTERS)\n",
    "    fig_map = create_interactive_map(lon, lat, lat_points, lon_points, colors)\n",
    "else:\n",
    "    colored_mask = create_colored_mask_image(segmentation, N_CLUSTERS)\n",
    "    colored_mask.save('segmented_image.png')\n",
    "    fig_map = create_map_overlay(lon, lat, colored_mask=colored_mask)\n",
    "\n",
    "\n",
    "class_proportions = calculate_class_proportions(segmentation, N_CLUSTERS)\n",
    "fig_distribution = create_class_distribution_pie_chart(class_proportions)\n",
    "\n",
    "\n",
    "fig_map.show()\n",
    "fig_distribution.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
